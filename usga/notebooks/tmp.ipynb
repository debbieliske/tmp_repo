{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25660a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import logging\n",
    "from neo4j import GraphDatabase\n",
    "import fitz  # PyMuPDF for PDF reading\n",
    "from typing import List, Any, Dict\n",
    "\n",
    "# Langchain imports\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.router import MultiRetrievalQAChain\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "\n",
    "# For custom router prompt in MultiRetrievalQAChain\n",
    "from langchain.chains.router.llm_router import RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import ROUTER_TEMPLATE\n",
    "\n",
    "\n",
    "# Optional NLP imports (assuming they are the same)\n",
    "# ...\n",
    "\n",
    "# Configuration (assuming they are the same)\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASS = os.getenv(\"NEO4J_PASS\", \"password\")\n",
    "pdf_path = os.getenv(\"PDF_PATH\", \"your_pdf_path.pdf\") # Update this\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Neo4j Data Ingestion Script (Placeholder - Use your full script) ---\n",
    "neo4j_ingestion_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "def populate_data_from_pdf(): logging.info(\"Placeholder: PDF data population.\")\n",
    "def save_to_neo4j(): logging.info(\"Placeholder: Saving to Neo4j.\")\n",
    "# --- End of Ingestion Placeholder ---\n",
    "\n",
    "def create_neo4j_ft_index(driver_param: GraphDatabase.driver):\n",
    "    with driver_param.session() as session:\n",
    "        try:\n",
    "            index_query = \"\"\"\n",
    "            CREATE FULLTEXT INDEX ruleTextIndex IF NOT EXISTS\n",
    "            FOR (n:RuleSection|Clarification) ON EACH [n.title, n.text]\n",
    "            \"\"\"\n",
    "            session.run(index_query)\n",
    "            logging.info(\"Full-text index 'ruleTextIndex' ensured or already exists.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error ensuring Neo4j full-text index: {e}\")\n",
    "\n",
    "class SimpleNeo4jRetriever(BaseRetriever):\n",
    "    driver: Any \n",
    "    limit: int = 5\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        results: List[Document] = []\n",
    "        logging.debug(f\"SimpleNeo4jRetriever _get_relevant_documents for user query: '{query}'\")\n",
    "        \n",
    "        # FIX 1: Changed $query to $search_term in Cypher and in session.run call\n",
    "        cypher_statement = \"\"\"\n",
    "        CALL db.index.fulltext.queryNodes('ruleTextIndex', $search_term) YIELD node, score\n",
    "        WITH node, score \n",
    "        WHERE node.id IS NOT NULL AND (node.title IS NOT NULL OR node.text IS NOT NULL)\n",
    "        RETURN node.id AS id, \n",
    "               coalesce(node.title, \"\") AS title, \n",
    "               coalesce(node.text, \"\") AS text, \n",
    "               score\n",
    "        ORDER BY score DESC\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            try:\n",
    "                records = session.run(cypher_statement, search_term=query, limit=self.limit) \n",
    "                for rec in records:\n",
    "                    page_content_parts = []\n",
    "                    if rec[\"title\"]: page_content_parts.append(rec[\"title\"])\n",
    "                    if rec[\"text\"]: page_content_parts.append(rec[\"text\"])\n",
    "                    content = \"\\n\\n\".join(page_content_parts).strip()\n",
    "                    if not content: continue\n",
    "                    metadata = {\"rule_id\": str(rec[\"id\"]), \"score\": rec[\"score\"]}\n",
    "                    results.append(Document(page_content=content, metadata=metadata))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Neo4j full-text search failed in _get_relevant_documents: {e}\", exc_info=True) # Added exc_info\n",
    "                if \"No such index\" in str(e) or \"index does not exist\" in str(e):\n",
    "                    logging.error(\"The 'ruleTextIndex' does not exist.\")\n",
    "        logging.debug(f\"SimpleNeo4jRetriever _get_relevant_documents returning {len(results)} documents.\")\n",
    "        return results\n",
    "\n",
    "class MockVectorRetriever(BaseRetriever):\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        logging.debug(f\"MockVectorRetriever _get_relevant_documents for query: '{query}'\")\n",
    "        return [Document(page_content=f\"Mock vector content for: {query}\", metadata={\"rule_id\": \"Rule Vector.Mock\"})]\n",
    "\n",
    "def run_qa_system():\n",
    "    qa_neo4j_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "    create_neo4j_ft_index(qa_neo4j_driver)\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    qa_prompt_for_input_key = PromptTemplate(\n",
    "        input_variables=[\"context\", \"input\"],\n",
    "        template=( \"...\") # Your prompt template here\n",
    "    )\n",
    "    qa_prompt_for_query_key = PromptTemplate(\n",
    "        input_variables=[\"context\", \"query\"],\n",
    "        template=( \"...\") # Your prompt template here\n",
    "    )\n",
    "    # Fill in your prompt templates:\n",
    "    qa_prompt_for_input_key = PromptTemplate(\n",
    "        input_variables=[\"context\", \"input\"],\n",
    "        template=(\n",
    "            \"Use the following context to answer the question precisely. \"\n",
    "            \"If it’s not in the context, say “I don’t know.”\\n\\n\"\n",
    "            \"Context:\\n{context}\\n\\nQuestion: {input}\\nAnswer:\"\n",
    "        )\n",
    "    )\n",
    "    qa_prompt_for_query_key = PromptTemplate(\n",
    "        input_variables=[\"context\", \"query\"],\n",
    "        template=(\n",
    "            \"Use the following context to answer the question precisely. \"\n",
    "            \"If it’s not in the context, say “I don’t know.”\\n\\n\"\n",
    "            \"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    combine_docs_chain_for_input = create_stuff_documents_chain(llm=llm, prompt=qa_prompt_for_input_key)\n",
    "    vector_retriever = MockVectorRetriever() \n",
    "    graph_retriever_instance = SimpleNeo4jRetriever(driver=qa_neo4j_driver, limit=5)\n",
    "    vector_chain = create_retrieval_chain(vector_retriever, combine_docs_chain_for_input)\n",
    "    graph_chain = create_retrieval_chain(graph_retriever_instance, combine_docs_chain_for_input)\n",
    "\n",
    "    # FIX 2: Custom router prompt for MultiRetrievalQAChain to use \"query\"\n",
    "    custom_router_template_str = ROUTER_TEMPLATE.replace(\"{input}\", \"{query}\")\n",
    "    router_prompt = PromptTemplate(\n",
    "        template=custom_router_template_str,\n",
    "        input_variables=[\"query\", \"destinations\"], # Changed from \"input\"\n",
    "        output_parser=RouterOutputParser(),\n",
    "    )\n",
    "\n",
    "    multi_chain = MultiRetrievalQAChain.from_retrievers(\n",
    "        llm=llm, \n",
    "        retriever_infos=[\n",
    "            {\"name\": \"vector_search\", \"description\": \"Good for semantic similarity...\", \"retriever\": vector_retriever},\n",
    "            {\"name\": \"graph_search\",  \"description\": \"Good for specific rule lookup...\", \"retriever\": graph_retriever_instance},\n",
    "        ],\n",
    "        default_retriever=vector_retriever,\n",
    "        default_prompt=qa_prompt_for_query_key, # For the QA part, uses \"query\"\n",
    "        default_chain_llm=llm, \n",
    "        verbose=True,\n",
    "        router_prompt=router_prompt # Use the custom router prompt\n",
    "    )\n",
    "\n",
    "    QUERIES = [\n",
    "        \"What happens when a ball is moved by an outside influence?\",\n",
    "        \"Which rules reference Rule 16?\",\n",
    "    ]\n",
    "    run_retrieval_comparison_tests(QUERIES, vector_chain, graph_chain, multi_chain)\n",
    "    qa_neo4j_driver.close()\n",
    "\n",
    "def extract_answer(output: Any) -> str:\n",
    "    # ... (same as before)\n",
    "    if isinstance(output, dict):\n",
    "        for key in (\"answer\", \"result\", \"text\"): \n",
    "            if key in output and output[key] is not None:\n",
    "                return str(output[key])\n",
    "        for value in output.values(): # Fallback\n",
    "            if isinstance(value, str): return value\n",
    "        return f\"<NO_ANSWER_KEY_IN_DICT: {output}>\"\n",
    "    return str(output)\n",
    "\n",
    "\n",
    "def run_retrieval_comparison_tests(queries_list, vc, gc, mc):\n",
    "    # FIX 2 (part 2): Call Hybrid chain with \"query\" as input key\n",
    "    test_scenarios = [\n",
    "        (\"Vector-only\", vc, \"input\"),\n",
    "        (\"Graph-only\",  gc, \"input\"),\n",
    "        (\"Hybrid\",      mc, \"query\"), # Changed to \"query\"\n",
    "    ]\n",
    "    for q_idx, q_text in enumerate(queries_list):\n",
    "        print(f\"\\n=== Query {q_idx+1}: {q_text!r} ===\")\n",
    "        for label, chain_instance, input_key_name in test_scenarios:\n",
    "            ans_output = \"<NOT_RUN>\"\n",
    "            try:\n",
    "                logging.info(f\"Running chain '{label}' with input key '{input_key_name}' for query: '{q_text}'\")\n",
    "                input_payload = {input_key_name: q_text}\n",
    "                # A bit of introspection to see what keys the chain expects\n",
    "                # if hasattr(chain_instance, 'input_keys'):\n",
    "                #    logging.debug(f\"Chain '{label}' expects input_keys: {chain_instance.input_keys}\")\n",
    "                # else:\n",
    "                #    logging.debug(f\"Chain '{label}' does not have 'input_keys' attribute.\")\n",
    "\n",
    "                chain_response = chain_instance.invoke(input_payload)\n",
    "                ans_output = extract_answer(chain_response)\n",
    "                print(f\"{label.ljust(14)}: {ans_output}\")\n",
    "            except Exception as e:\n",
    "                error_detail = f\"<ERROR: {type(e).__name__} - {e}>\"\n",
    "                logging.error(f\"Error running {label} for query '{q_text}': {error_detail}\", exc_info=True) \n",
    "                print(f\"{label.ljust(14)}: {error_detail}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # print(\"Starting Neo4j data ingestion process...\")\n",
    "    # save_to_neo4j() # Ensure your full ingestion code is uncommented here if needed\n",
    "    # print(\"Neo4j data ingestion process complete.\")\n",
    "    if 'neo4j_ingestion_driver' in globals() and neo4j_ingestion_driver:\n",
    "         try: neo4j_ingestion_driver.close(); logging.info(\"Neo4j ingestion driver closed.\")\n",
    "         except: pass\n",
    "    print(\"\\nStarting QA System...\")\n",
    "    run_qa_system()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
