{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c5818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5fd5b2b",
   "metadata": {},
   "source": [
    "# Basic Pipeline\n",
    "\n",
    "1. Extract the PDF into text (using PyMuPDF for structure).\n",
    "2. Chunk and embed text with OpenAI’s ADA.\n",
    "3. Store embeddings in ChromaDB.\n",
    "4. Ingest each Rule (and its references) into Neo4j via Cypher.\n",
    "5. Build a hybrid RAG retriever that combines vector and graph queries.\n",
    "6. Wire up a LangChain chain using GPT-4o to generate precise, rule-based answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1607b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf langchain chromadb neo4j openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d777e12",
   "metadata": {},
   "source": [
    "#  Load and parse the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776f34f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_pages(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages = []\n",
    "    for page in doc:\n",
    "        text = page.get_text(\"text\")\n",
    "        pages.append(text)\n",
    "    return pages\n",
    "\n",
    "pages = extract_pages(\"../data/Rules of Golf for 2019 (Final).pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def34e5e",
   "metadata": {},
   "source": [
    "# Chunk and embed with ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r0/ptjpfbhd6x76hdl0g4ghgx540000gn/T/ipykernel_37413/4041581904.py:18: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedder = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "# Split into ~500-token chunks with overlap\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=200\n",
    ")\n",
    "docs = []\n",
    "for i, page in enumerate(pages):\n",
    "    for chunk in splitter.split_text(page):\n",
    "        docs.append({\"page\": i+1, \"text\": chunk})\n",
    "\n",
    "# Create embeddings\n",
    "embedder = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "texts = [d[\"text\"] for d in docs]\n",
    "metadatas = [{\"page\": d[\"page\"]} for d in docs]\n",
    "embeddings = embedder.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6687a236",
   "metadata": {},
   "source": [
    "# Persist to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51691dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: chunk_0\n",
      "Add of existing embedding ID: chunk_1\n",
      "Add of existing embedding ID: chunk_2\n",
      "Add of existing embedding ID: chunk_3\n",
      "Add of existing embedding ID: chunk_4\n",
      "Add of existing embedding ID: chunk_5\n",
      "Add of existing embedding ID: chunk_6\n",
      "Add of existing embedding ID: chunk_7\n",
      "Add of existing embedding ID: chunk_8\n",
      "Add of existing embedding ID: chunk_9\n",
      "Add of existing embedding ID: chunk_10\n",
      "Add of existing embedding ID: chunk_11\n",
      "Add of existing embedding ID: chunk_12\n",
      "Add of existing embedding ID: chunk_13\n",
      "Add of existing embedding ID: chunk_14\n",
      "Add of existing embedding ID: chunk_15\n",
      "Add of existing embedding ID: chunk_16\n",
      "Add of existing embedding ID: chunk_17\n",
      "Add of existing embedding ID: chunk_18\n",
      "Add of existing embedding ID: chunk_19\n",
      "Add of existing embedding ID: chunk_20\n",
      "Add of existing embedding ID: chunk_21\n",
      "Add of existing embedding ID: chunk_22\n",
      "Add of existing embedding ID: chunk_23\n",
      "Add of existing embedding ID: chunk_24\n",
      "Add of existing embedding ID: chunk_25\n",
      "Add of existing embedding ID: chunk_26\n",
      "Add of existing embedding ID: chunk_27\n",
      "Add of existing embedding ID: chunk_28\n",
      "Add of existing embedding ID: chunk_29\n",
      "Add of existing embedding ID: chunk_30\n",
      "Add of existing embedding ID: chunk_31\n",
      "Add of existing embedding ID: chunk_32\n",
      "Add of existing embedding ID: chunk_33\n",
      "Add of existing embedding ID: chunk_34\n",
      "Add of existing embedding ID: chunk_35\n",
      "Add of existing embedding ID: chunk_36\n",
      "Add of existing embedding ID: chunk_37\n",
      "Add of existing embedding ID: chunk_38\n",
      "Add of existing embedding ID: chunk_39\n",
      "Add of existing embedding ID: chunk_40\n",
      "Add of existing embedding ID: chunk_41\n",
      "Add of existing embedding ID: chunk_42\n",
      "Add of existing embedding ID: chunk_43\n",
      "Add of existing embedding ID: chunk_44\n",
      "Add of existing embedding ID: chunk_45\n",
      "Add of existing embedding ID: chunk_46\n",
      "Add of existing embedding ID: chunk_47\n",
      "Add of existing embedding ID: chunk_48\n",
      "Add of existing embedding ID: chunk_49\n",
      "Add of existing embedding ID: chunk_50\n",
      "Add of existing embedding ID: chunk_51\n",
      "Add of existing embedding ID: chunk_52\n",
      "Add of existing embedding ID: chunk_53\n",
      "Add of existing embedding ID: chunk_54\n",
      "Add of existing embedding ID: chunk_55\n",
      "Add of existing embedding ID: chunk_56\n",
      "Add of existing embedding ID: chunk_57\n",
      "Add of existing embedding ID: chunk_58\n",
      "Add of existing embedding ID: chunk_59\n",
      "Add of existing embedding ID: chunk_60\n",
      "Add of existing embedding ID: chunk_61\n",
      "Add of existing embedding ID: chunk_62\n",
      "Add of existing embedding ID: chunk_63\n",
      "Add of existing embedding ID: chunk_64\n",
      "Add of existing embedding ID: chunk_65\n",
      "Add of existing embedding ID: chunk_66\n",
      "Add of existing embedding ID: chunk_67\n",
      "Add of existing embedding ID: chunk_68\n",
      "Add of existing embedding ID: chunk_69\n",
      "Add of existing embedding ID: chunk_70\n",
      "Add of existing embedding ID: chunk_71\n",
      "Add of existing embedding ID: chunk_72\n",
      "Add of existing embedding ID: chunk_73\n",
      "Add of existing embedding ID: chunk_74\n",
      "Add of existing embedding ID: chunk_75\n",
      "Add of existing embedding ID: chunk_76\n",
      "Add of existing embedding ID: chunk_77\n",
      "Add of existing embedding ID: chunk_78\n",
      "Add of existing embedding ID: chunk_79\n",
      "Add of existing embedding ID: chunk_80\n",
      "Add of existing embedding ID: chunk_81\n",
      "Add of existing embedding ID: chunk_82\n",
      "Add of existing embedding ID: chunk_83\n",
      "Add of existing embedding ID: chunk_84\n",
      "Add of existing embedding ID: chunk_85\n",
      "Add of existing embedding ID: chunk_86\n",
      "Add of existing embedding ID: chunk_87\n",
      "Add of existing embedding ID: chunk_88\n",
      "Add of existing embedding ID: chunk_89\n",
      "Add of existing embedding ID: chunk_90\n",
      "Add of existing embedding ID: chunk_91\n",
      "Add of existing embedding ID: chunk_92\n",
      "Add of existing embedding ID: chunk_93\n",
      "Add of existing embedding ID: chunk_94\n",
      "Add of existing embedding ID: chunk_95\n",
      "Add of existing embedding ID: chunk_96\n",
      "Add of existing embedding ID: chunk_97\n",
      "Add of existing embedding ID: chunk_98\n",
      "Add of existing embedding ID: chunk_99\n",
      "Add of existing embedding ID: chunk_100\n",
      "Add of existing embedding ID: chunk_101\n",
      "Add of existing embedding ID: chunk_102\n",
      "Add of existing embedding ID: chunk_103\n",
      "Add of existing embedding ID: chunk_104\n",
      "Add of existing embedding ID: chunk_105\n",
      "Add of existing embedding ID: chunk_106\n",
      "Add of existing embedding ID: chunk_107\n",
      "Add of existing embedding ID: chunk_108\n",
      "Add of existing embedding ID: chunk_109\n",
      "Add of existing embedding ID: chunk_110\n",
      "Add of existing embedding ID: chunk_111\n",
      "Add of existing embedding ID: chunk_112\n",
      "Add of existing embedding ID: chunk_113\n",
      "Add of existing embedding ID: chunk_114\n",
      "Add of existing embedding ID: chunk_115\n",
      "Add of existing embedding ID: chunk_116\n",
      "Add of existing embedding ID: chunk_117\n",
      "Add of existing embedding ID: chunk_118\n",
      "Add of existing embedding ID: chunk_119\n",
      "Add of existing embedding ID: chunk_120\n",
      "Add of existing embedding ID: chunk_121\n",
      "Add of existing embedding ID: chunk_122\n",
      "Add of existing embedding ID: chunk_123\n",
      "Add of existing embedding ID: chunk_124\n",
      "Add of existing embedding ID: chunk_125\n",
      "Add of existing embedding ID: chunk_126\n",
      "Add of existing embedding ID: chunk_127\n",
      "Add of existing embedding ID: chunk_128\n",
      "Add of existing embedding ID: chunk_129\n",
      "Add of existing embedding ID: chunk_130\n",
      "Add of existing embedding ID: chunk_131\n",
      "Add of existing embedding ID: chunk_132\n",
      "Add of existing embedding ID: chunk_133\n",
      "Add of existing embedding ID: chunk_134\n",
      "Add of existing embedding ID: chunk_135\n",
      "Add of existing embedding ID: chunk_136\n",
      "Add of existing embedding ID: chunk_137\n",
      "Add of existing embedding ID: chunk_138\n",
      "Add of existing embedding ID: chunk_139\n",
      "Add of existing embedding ID: chunk_140\n",
      "Add of existing embedding ID: chunk_141\n",
      "Add of existing embedding ID: chunk_142\n",
      "Add of existing embedding ID: chunk_143\n",
      "Add of existing embedding ID: chunk_144\n",
      "Add of existing embedding ID: chunk_145\n",
      "Add of existing embedding ID: chunk_146\n",
      "Add of existing embedding ID: chunk_147\n",
      "Add of existing embedding ID: chunk_148\n",
      "Add of existing embedding ID: chunk_149\n",
      "Add of existing embedding ID: chunk_150\n",
      "Add of existing embedding ID: chunk_151\n",
      "Add of existing embedding ID: chunk_152\n",
      "Add of existing embedding ID: chunk_153\n",
      "Add of existing embedding ID: chunk_154\n",
      "Add of existing embedding ID: chunk_155\n",
      "Add of existing embedding ID: chunk_156\n",
      "Add of existing embedding ID: chunk_157\n",
      "Add of existing embedding ID: chunk_158\n",
      "Add of existing embedding ID: chunk_159\n",
      "Add of existing embedding ID: chunk_160\n",
      "Add of existing embedding ID: chunk_161\n",
      "Add of existing embedding ID: chunk_162\n",
      "Add of existing embedding ID: chunk_163\n",
      "Add of existing embedding ID: chunk_164\n",
      "Add of existing embedding ID: chunk_165\n",
      "Add of existing embedding ID: chunk_166\n",
      "Add of existing embedding ID: chunk_167\n",
      "Add of existing embedding ID: chunk_168\n",
      "Add of existing embedding ID: chunk_169\n",
      "Add of existing embedding ID: chunk_170\n",
      "Add of existing embedding ID: chunk_171\n",
      "Add of existing embedding ID: chunk_172\n",
      "Add of existing embedding ID: chunk_173\n",
      "Add of existing embedding ID: chunk_174\n",
      "Add of existing embedding ID: chunk_175\n",
      "Add of existing embedding ID: chunk_176\n",
      "Add of existing embedding ID: chunk_177\n",
      "Add of existing embedding ID: chunk_178\n",
      "Add of existing embedding ID: chunk_179\n",
      "Add of existing embedding ID: chunk_180\n",
      "Add of existing embedding ID: chunk_181\n",
      "Add of existing embedding ID: chunk_182\n",
      "Add of existing embedding ID: chunk_183\n",
      "Add of existing embedding ID: chunk_184\n",
      "Add of existing embedding ID: chunk_185\n",
      "Add of existing embedding ID: chunk_186\n",
      "Add of existing embedding ID: chunk_187\n",
      "Add of existing embedding ID: chunk_188\n",
      "Add of existing embedding ID: chunk_189\n",
      "Add of existing embedding ID: chunk_190\n",
      "Add of existing embedding ID: chunk_191\n",
      "Add of existing embedding ID: chunk_192\n",
      "Add of existing embedding ID: chunk_193\n",
      "Add of existing embedding ID: chunk_194\n",
      "Add of existing embedding ID: chunk_195\n",
      "Add of existing embedding ID: chunk_196\n",
      "Add of existing embedding ID: chunk_197\n",
      "Add of existing embedding ID: chunk_198\n",
      "Add of existing embedding ID: chunk_199\n",
      "Add of existing embedding ID: chunk_200\n",
      "Add of existing embedding ID: chunk_201\n",
      "Add of existing embedding ID: chunk_202\n",
      "Add of existing embedding ID: chunk_203\n",
      "Add of existing embedding ID: chunk_204\n",
      "Add of existing embedding ID: chunk_205\n",
      "Add of existing embedding ID: chunk_206\n",
      "Add of existing embedding ID: chunk_207\n",
      "Add of existing embedding ID: chunk_208\n",
      "Add of existing embedding ID: chunk_209\n",
      "Add of existing embedding ID: chunk_210\n",
      "Add of existing embedding ID: chunk_211\n",
      "Add of existing embedding ID: chunk_212\n",
      "Add of existing embedding ID: chunk_213\n",
      "Add of existing embedding ID: chunk_214\n",
      "Add of existing embedding ID: chunk_215\n",
      "Add of existing embedding ID: chunk_216\n",
      "Add of existing embedding ID: chunk_217\n",
      "Add of existing embedding ID: chunk_218\n",
      "Add of existing embedding ID: chunk_219\n",
      "Add of existing embedding ID: chunk_220\n",
      "Add of existing embedding ID: chunk_221\n",
      "Add of existing embedding ID: chunk_222\n",
      "Add of existing embedding ID: chunk_223\n",
      "Add of existing embedding ID: chunk_224\n",
      "Add of existing embedding ID: chunk_225\n",
      "Add of existing embedding ID: chunk_226\n",
      "Add of existing embedding ID: chunk_227\n",
      "Add of existing embedding ID: chunk_228\n",
      "Add of existing embedding ID: chunk_229\n",
      "Add of existing embedding ID: chunk_230\n",
      "Add of existing embedding ID: chunk_231\n",
      "Add of existing embedding ID: chunk_232\n",
      "Add of existing embedding ID: chunk_233\n",
      "Add of existing embedding ID: chunk_234\n",
      "Add of existing embedding ID: chunk_235\n",
      "Add of existing embedding ID: chunk_236\n",
      "Add of existing embedding ID: chunk_237\n",
      "Add of existing embedding ID: chunk_238\n",
      "Add of existing embedding ID: chunk_239\n",
      "Add of existing embedding ID: chunk_240\n",
      "Add of existing embedding ID: chunk_241\n",
      "Add of existing embedding ID: chunk_242\n",
      "Add of existing embedding ID: chunk_243\n",
      "Add of existing embedding ID: chunk_244\n",
      "Add of existing embedding ID: chunk_245\n",
      "Add of existing embedding ID: chunk_246\n",
      "Add of existing embedding ID: chunk_247\n",
      "Add of existing embedding ID: chunk_248\n",
      "Add of existing embedding ID: chunk_249\n",
      "Add of existing embedding ID: chunk_250\n",
      "Add of existing embedding ID: chunk_251\n",
      "Add of existing embedding ID: chunk_252\n",
      "Add of existing embedding ID: chunk_253\n",
      "Add of existing embedding ID: chunk_254\n",
      "Add of existing embedding ID: chunk_255\n",
      "Add of existing embedding ID: chunk_256\n",
      "Add of existing embedding ID: chunk_257\n",
      "Add of existing embedding ID: chunk_258\n",
      "Add of existing embedding ID: chunk_259\n",
      "Add of existing embedding ID: chunk_260\n",
      "Add of existing embedding ID: chunk_261\n",
      "Add of existing embedding ID: chunk_262\n",
      "Add of existing embedding ID: chunk_263\n",
      "Add of existing embedding ID: chunk_264\n",
      "Add of existing embedding ID: chunk_265\n",
      "Add of existing embedding ID: chunk_266\n",
      "Add of existing embedding ID: chunk_267\n",
      "Add of existing embedding ID: chunk_268\n",
      "Add of existing embedding ID: chunk_269\n",
      "Add of existing embedding ID: chunk_270\n",
      "Add of existing embedding ID: chunk_271\n",
      "Add of existing embedding ID: chunk_272\n",
      "Add of existing embedding ID: chunk_273\n",
      "Add of existing embedding ID: chunk_274\n",
      "Add of existing embedding ID: chunk_275\n",
      "Add of existing embedding ID: chunk_276\n",
      "Add of existing embedding ID: chunk_277\n",
      "Add of existing embedding ID: chunk_278\n",
      "Add of existing embedding ID: chunk_279\n",
      "Add of existing embedding ID: chunk_280\n",
      "Add of existing embedding ID: chunk_281\n",
      "Add of existing embedding ID: chunk_282\n",
      "Add of existing embedding ID: chunk_283\n",
      "Add of existing embedding ID: chunk_284\n",
      "Add of existing embedding ID: chunk_285\n",
      "Add of existing embedding ID: chunk_286\n",
      "Add of existing embedding ID: chunk_287\n",
      "Add of existing embedding ID: chunk_288\n",
      "Add of existing embedding ID: chunk_289\n",
      "Add of existing embedding ID: chunk_290\n",
      "Add of existing embedding ID: chunk_291\n",
      "Add of existing embedding ID: chunk_292\n",
      "Add of existing embedding ID: chunk_293\n",
      "Add of existing embedding ID: chunk_294\n",
      "Add of existing embedding ID: chunk_295\n",
      "Add of existing embedding ID: chunk_296\n",
      "Add of existing embedding ID: chunk_297\n",
      "Add of existing embedding ID: chunk_298\n",
      "Add of existing embedding ID: chunk_299\n",
      "Add of existing embedding ID: chunk_300\n",
      "Add of existing embedding ID: chunk_301\n",
      "Add of existing embedding ID: chunk_302\n",
      "Add of existing embedding ID: chunk_303\n",
      "Add of existing embedding ID: chunk_304\n",
      "Add of existing embedding ID: chunk_305\n",
      "Add of existing embedding ID: chunk_306\n",
      "Add of existing embedding ID: chunk_307\n",
      "Add of existing embedding ID: chunk_308\n",
      "Add of existing embedding ID: chunk_309\n",
      "Add of existing embedding ID: chunk_310\n",
      "Add of existing embedding ID: chunk_311\n",
      "Add of existing embedding ID: chunk_312\n",
      "Add of existing embedding ID: chunk_313\n",
      "Add of existing embedding ID: chunk_314\n",
      "Add of existing embedding ID: chunk_315\n",
      "Insert of existing embedding ID: chunk_0\n",
      "Insert of existing embedding ID: chunk_1\n",
      "Insert of existing embedding ID: chunk_2\n",
      "Insert of existing embedding ID: chunk_3\n",
      "Insert of existing embedding ID: chunk_4\n",
      "Insert of existing embedding ID: chunk_5\n",
      "Insert of existing embedding ID: chunk_6\n",
      "Insert of existing embedding ID: chunk_7\n",
      "Insert of existing embedding ID: chunk_8\n",
      "Insert of existing embedding ID: chunk_9\n",
      "Insert of existing embedding ID: chunk_10\n",
      "Insert of existing embedding ID: chunk_11\n",
      "Insert of existing embedding ID: chunk_12\n",
      "Insert of existing embedding ID: chunk_13\n",
      "Insert of existing embedding ID: chunk_14\n",
      "Insert of existing embedding ID: chunk_15\n",
      "Insert of existing embedding ID: chunk_16\n",
      "Insert of existing embedding ID: chunk_17\n",
      "Insert of existing embedding ID: chunk_18\n",
      "Insert of existing embedding ID: chunk_19\n",
      "Insert of existing embedding ID: chunk_20\n",
      "Insert of existing embedding ID: chunk_21\n",
      "Insert of existing embedding ID: chunk_22\n",
      "Insert of existing embedding ID: chunk_23\n",
      "Insert of existing embedding ID: chunk_24\n",
      "Insert of existing embedding ID: chunk_25\n",
      "Insert of existing embedding ID: chunk_26\n",
      "Insert of existing embedding ID: chunk_27\n",
      "Insert of existing embedding ID: chunk_28\n",
      "Insert of existing embedding ID: chunk_29\n",
      "Insert of existing embedding ID: chunk_30\n",
      "Insert of existing embedding ID: chunk_31\n",
      "Insert of existing embedding ID: chunk_32\n",
      "Insert of existing embedding ID: chunk_33\n",
      "Insert of existing embedding ID: chunk_34\n",
      "Insert of existing embedding ID: chunk_35\n",
      "Insert of existing embedding ID: chunk_36\n",
      "Insert of existing embedding ID: chunk_37\n",
      "Insert of existing embedding ID: chunk_38\n",
      "Insert of existing embedding ID: chunk_39\n",
      "Insert of existing embedding ID: chunk_40\n",
      "Insert of existing embedding ID: chunk_41\n",
      "Insert of existing embedding ID: chunk_42\n",
      "Insert of existing embedding ID: chunk_43\n",
      "Insert of existing embedding ID: chunk_44\n",
      "Insert of existing embedding ID: chunk_45\n",
      "Insert of existing embedding ID: chunk_46\n",
      "Insert of existing embedding ID: chunk_47\n",
      "Insert of existing embedding ID: chunk_48\n",
      "Insert of existing embedding ID: chunk_49\n",
      "Insert of existing embedding ID: chunk_50\n",
      "Insert of existing embedding ID: chunk_51\n",
      "Insert of existing embedding ID: chunk_52\n",
      "Insert of existing embedding ID: chunk_53\n",
      "Insert of existing embedding ID: chunk_54\n",
      "Insert of existing embedding ID: chunk_55\n",
      "Insert of existing embedding ID: chunk_56\n",
      "Insert of existing embedding ID: chunk_57\n",
      "Insert of existing embedding ID: chunk_58\n",
      "Insert of existing embedding ID: chunk_59\n",
      "Insert of existing embedding ID: chunk_60\n",
      "Insert of existing embedding ID: chunk_61\n",
      "Insert of existing embedding ID: chunk_62\n",
      "Insert of existing embedding ID: chunk_63\n",
      "Insert of existing embedding ID: chunk_64\n",
      "Insert of existing embedding ID: chunk_65\n",
      "Insert of existing embedding ID: chunk_66\n",
      "Insert of existing embedding ID: chunk_67\n",
      "Insert of existing embedding ID: chunk_68\n",
      "Insert of existing embedding ID: chunk_69\n",
      "Insert of existing embedding ID: chunk_70\n",
      "Insert of existing embedding ID: chunk_71\n",
      "Insert of existing embedding ID: chunk_72\n",
      "Insert of existing embedding ID: chunk_73\n",
      "Insert of existing embedding ID: chunk_74\n",
      "Insert of existing embedding ID: chunk_75\n",
      "Insert of existing embedding ID: chunk_76\n",
      "Insert of existing embedding ID: chunk_77\n",
      "Insert of existing embedding ID: chunk_78\n",
      "Insert of existing embedding ID: chunk_79\n",
      "Insert of existing embedding ID: chunk_80\n",
      "Insert of existing embedding ID: chunk_81\n",
      "Insert of existing embedding ID: chunk_82\n",
      "Insert of existing embedding ID: chunk_83\n",
      "Insert of existing embedding ID: chunk_84\n",
      "Insert of existing embedding ID: chunk_85\n",
      "Insert of existing embedding ID: chunk_86\n",
      "Insert of existing embedding ID: chunk_87\n",
      "Insert of existing embedding ID: chunk_88\n",
      "Insert of existing embedding ID: chunk_89\n",
      "Insert of existing embedding ID: chunk_90\n",
      "Insert of existing embedding ID: chunk_91\n",
      "Insert of existing embedding ID: chunk_92\n",
      "Insert of existing embedding ID: chunk_93\n",
      "Insert of existing embedding ID: chunk_94\n",
      "Insert of existing embedding ID: chunk_95\n",
      "Insert of existing embedding ID: chunk_96\n",
      "Insert of existing embedding ID: chunk_97\n",
      "Insert of existing embedding ID: chunk_98\n",
      "Insert of existing embedding ID: chunk_99\n",
      "Insert of existing embedding ID: chunk_100\n",
      "Insert of existing embedding ID: chunk_101\n",
      "Insert of existing embedding ID: chunk_102\n",
      "Insert of existing embedding ID: chunk_103\n",
      "Insert of existing embedding ID: chunk_104\n",
      "Insert of existing embedding ID: chunk_105\n",
      "Insert of existing embedding ID: chunk_106\n",
      "Insert of existing embedding ID: chunk_107\n",
      "Insert of existing embedding ID: chunk_108\n",
      "Insert of existing embedding ID: chunk_109\n",
      "Insert of existing embedding ID: chunk_110\n",
      "Insert of existing embedding ID: chunk_111\n",
      "Insert of existing embedding ID: chunk_112\n",
      "Insert of existing embedding ID: chunk_113\n",
      "Insert of existing embedding ID: chunk_114\n",
      "Insert of existing embedding ID: chunk_115\n",
      "Insert of existing embedding ID: chunk_116\n",
      "Insert of existing embedding ID: chunk_117\n",
      "Insert of existing embedding ID: chunk_118\n",
      "Insert of existing embedding ID: chunk_119\n",
      "Insert of existing embedding ID: chunk_120\n",
      "Insert of existing embedding ID: chunk_121\n",
      "Insert of existing embedding ID: chunk_122\n",
      "Insert of existing embedding ID: chunk_123\n",
      "Insert of existing embedding ID: chunk_124\n",
      "Insert of existing embedding ID: chunk_125\n",
      "Insert of existing embedding ID: chunk_126\n",
      "Insert of existing embedding ID: chunk_127\n",
      "Insert of existing embedding ID: chunk_128\n",
      "Insert of existing embedding ID: chunk_129\n",
      "Insert of existing embedding ID: chunk_130\n",
      "Insert of existing embedding ID: chunk_131\n",
      "Insert of existing embedding ID: chunk_132\n",
      "Insert of existing embedding ID: chunk_133\n",
      "Insert of existing embedding ID: chunk_134\n",
      "Insert of existing embedding ID: chunk_135\n",
      "Insert of existing embedding ID: chunk_136\n",
      "Insert of existing embedding ID: chunk_137\n",
      "Insert of existing embedding ID: chunk_138\n",
      "Insert of existing embedding ID: chunk_139\n",
      "Insert of existing embedding ID: chunk_140\n",
      "Insert of existing embedding ID: chunk_141\n",
      "Insert of existing embedding ID: chunk_142\n",
      "Insert of existing embedding ID: chunk_143\n",
      "Insert of existing embedding ID: chunk_144\n",
      "Insert of existing embedding ID: chunk_145\n",
      "Insert of existing embedding ID: chunk_146\n",
      "Insert of existing embedding ID: chunk_147\n",
      "Insert of existing embedding ID: chunk_148\n",
      "Insert of existing embedding ID: chunk_149\n",
      "Insert of existing embedding ID: chunk_150\n",
      "Insert of existing embedding ID: chunk_151\n",
      "Insert of existing embedding ID: chunk_152\n",
      "Insert of existing embedding ID: chunk_153\n",
      "Insert of existing embedding ID: chunk_154\n",
      "Insert of existing embedding ID: chunk_155\n",
      "Insert of existing embedding ID: chunk_156\n",
      "Insert of existing embedding ID: chunk_157\n",
      "Insert of existing embedding ID: chunk_158\n",
      "Insert of existing embedding ID: chunk_159\n",
      "Insert of existing embedding ID: chunk_160\n",
      "Insert of existing embedding ID: chunk_161\n",
      "Insert of existing embedding ID: chunk_162\n",
      "Insert of existing embedding ID: chunk_163\n",
      "Insert of existing embedding ID: chunk_164\n",
      "Insert of existing embedding ID: chunk_165\n",
      "Insert of existing embedding ID: chunk_166\n",
      "Insert of existing embedding ID: chunk_167\n",
      "Insert of existing embedding ID: chunk_168\n",
      "Insert of existing embedding ID: chunk_169\n",
      "Insert of existing embedding ID: chunk_170\n",
      "Insert of existing embedding ID: chunk_171\n",
      "Insert of existing embedding ID: chunk_172\n",
      "Insert of existing embedding ID: chunk_173\n",
      "Insert of existing embedding ID: chunk_174\n",
      "Insert of existing embedding ID: chunk_175\n",
      "Insert of existing embedding ID: chunk_176\n",
      "Insert of existing embedding ID: chunk_177\n",
      "Insert of existing embedding ID: chunk_178\n",
      "Insert of existing embedding ID: chunk_179\n",
      "Insert of existing embedding ID: chunk_180\n",
      "Insert of existing embedding ID: chunk_181\n",
      "Insert of existing embedding ID: chunk_182\n",
      "Insert of existing embedding ID: chunk_183\n",
      "Insert of existing embedding ID: chunk_184\n",
      "Insert of existing embedding ID: chunk_185\n",
      "Insert of existing embedding ID: chunk_186\n",
      "Insert of existing embedding ID: chunk_187\n",
      "Insert of existing embedding ID: chunk_188\n",
      "Insert of existing embedding ID: chunk_189\n",
      "Insert of existing embedding ID: chunk_190\n",
      "Insert of existing embedding ID: chunk_191\n",
      "Insert of existing embedding ID: chunk_192\n",
      "Insert of existing embedding ID: chunk_193\n",
      "Insert of existing embedding ID: chunk_194\n",
      "Insert of existing embedding ID: chunk_195\n",
      "Insert of existing embedding ID: chunk_196\n",
      "Insert of existing embedding ID: chunk_197\n",
      "Insert of existing embedding ID: chunk_198\n",
      "Insert of existing embedding ID: chunk_199\n",
      "Insert of existing embedding ID: chunk_200\n",
      "Insert of existing embedding ID: chunk_201\n",
      "Insert of existing embedding ID: chunk_202\n",
      "Insert of existing embedding ID: chunk_203\n",
      "Insert of existing embedding ID: chunk_204\n",
      "Insert of existing embedding ID: chunk_205\n",
      "Insert of existing embedding ID: chunk_206\n",
      "Insert of existing embedding ID: chunk_207\n",
      "Insert of existing embedding ID: chunk_208\n",
      "Insert of existing embedding ID: chunk_209\n",
      "Insert of existing embedding ID: chunk_210\n",
      "Insert of existing embedding ID: chunk_211\n",
      "Insert of existing embedding ID: chunk_212\n",
      "Insert of existing embedding ID: chunk_213\n",
      "Insert of existing embedding ID: chunk_214\n",
      "Insert of existing embedding ID: chunk_215\n",
      "Insert of existing embedding ID: chunk_216\n",
      "Insert of existing embedding ID: chunk_217\n",
      "Insert of existing embedding ID: chunk_218\n",
      "Insert of existing embedding ID: chunk_219\n",
      "Insert of existing embedding ID: chunk_220\n",
      "Insert of existing embedding ID: chunk_221\n",
      "Insert of existing embedding ID: chunk_222\n",
      "Insert of existing embedding ID: chunk_223\n",
      "Insert of existing embedding ID: chunk_224\n",
      "Insert of existing embedding ID: chunk_225\n",
      "Insert of existing embedding ID: chunk_226\n",
      "Insert of existing embedding ID: chunk_227\n",
      "Insert of existing embedding ID: chunk_228\n",
      "Insert of existing embedding ID: chunk_229\n",
      "Insert of existing embedding ID: chunk_230\n",
      "Insert of existing embedding ID: chunk_231\n",
      "Insert of existing embedding ID: chunk_232\n",
      "Insert of existing embedding ID: chunk_233\n",
      "Insert of existing embedding ID: chunk_234\n",
      "Insert of existing embedding ID: chunk_235\n",
      "Insert of existing embedding ID: chunk_236\n",
      "Insert of existing embedding ID: chunk_237\n",
      "Insert of existing embedding ID: chunk_238\n",
      "Insert of existing embedding ID: chunk_239\n",
      "Insert of existing embedding ID: chunk_240\n",
      "Insert of existing embedding ID: chunk_241\n",
      "Insert of existing embedding ID: chunk_242\n",
      "Insert of existing embedding ID: chunk_243\n",
      "Insert of existing embedding ID: chunk_244\n",
      "Insert of existing embedding ID: chunk_245\n",
      "Insert of existing embedding ID: chunk_246\n",
      "Insert of existing embedding ID: chunk_247\n",
      "Insert of existing embedding ID: chunk_248\n",
      "Insert of existing embedding ID: chunk_249\n",
      "Insert of existing embedding ID: chunk_250\n",
      "Insert of existing embedding ID: chunk_251\n",
      "Insert of existing embedding ID: chunk_252\n",
      "Insert of existing embedding ID: chunk_253\n",
      "Insert of existing embedding ID: chunk_254\n",
      "Insert of existing embedding ID: chunk_255\n",
      "Insert of existing embedding ID: chunk_256\n",
      "Insert of existing embedding ID: chunk_257\n",
      "Insert of existing embedding ID: chunk_258\n",
      "Insert of existing embedding ID: chunk_259\n",
      "Insert of existing embedding ID: chunk_260\n",
      "Insert of existing embedding ID: chunk_261\n",
      "Insert of existing embedding ID: chunk_262\n",
      "Insert of existing embedding ID: chunk_263\n",
      "Insert of existing embedding ID: chunk_264\n",
      "Insert of existing embedding ID: chunk_265\n",
      "Insert of existing embedding ID: chunk_266\n",
      "Insert of existing embedding ID: chunk_267\n",
      "Insert of existing embedding ID: chunk_268\n",
      "Insert of existing embedding ID: chunk_269\n",
      "Insert of existing embedding ID: chunk_270\n",
      "Insert of existing embedding ID: chunk_271\n",
      "Insert of existing embedding ID: chunk_272\n",
      "Insert of existing embedding ID: chunk_273\n",
      "Insert of existing embedding ID: chunk_274\n",
      "Insert of existing embedding ID: chunk_275\n",
      "Insert of existing embedding ID: chunk_276\n",
      "Insert of existing embedding ID: chunk_277\n",
      "Insert of existing embedding ID: chunk_278\n",
      "Insert of existing embedding ID: chunk_279\n",
      "Insert of existing embedding ID: chunk_280\n",
      "Insert of existing embedding ID: chunk_281\n",
      "Insert of existing embedding ID: chunk_282\n",
      "Insert of existing embedding ID: chunk_283\n",
      "Insert of existing embedding ID: chunk_284\n",
      "Insert of existing embedding ID: chunk_285\n",
      "Insert of existing embedding ID: chunk_286\n",
      "Insert of existing embedding ID: chunk_287\n",
      "Insert of existing embedding ID: chunk_288\n",
      "Insert of existing embedding ID: chunk_289\n",
      "Insert of existing embedding ID: chunk_290\n",
      "Insert of existing embedding ID: chunk_291\n",
      "Insert of existing embedding ID: chunk_292\n",
      "Insert of existing embedding ID: chunk_293\n",
      "Insert of existing embedding ID: chunk_294\n",
      "Insert of existing embedding ID: chunk_295\n",
      "Insert of existing embedding ID: chunk_296\n",
      "Insert of existing embedding ID: chunk_297\n",
      "Insert of existing embedding ID: chunk_298\n",
      "Insert of existing embedding ID: chunk_299\n",
      "Insert of existing embedding ID: chunk_300\n",
      "Insert of existing embedding ID: chunk_301\n",
      "Insert of existing embedding ID: chunk_302\n",
      "Insert of existing embedding ID: chunk_303\n",
      "Insert of existing embedding ID: chunk_304\n",
      "Insert of existing embedding ID: chunk_305\n",
      "Insert of existing embedding ID: chunk_306\n",
      "Insert of existing embedding ID: chunk_307\n",
      "Insert of existing embedding ID: chunk_308\n",
      "Insert of existing embedding ID: chunk_309\n",
      "Insert of existing embedding ID: chunk_310\n",
      "Insert of existing embedding ID: chunk_311\n",
      "Insert of existing embedding ID: chunk_312\n",
      "Insert of existing embedding ID: chunk_313\n",
      "Insert of existing embedding ID: chunk_314\n",
      "Insert of existing embedding ID: chunk_315\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "from chromadb.config import Settings, DEFAULT_TENANT, DEFAULT_DATABASE\n",
    "\n",
    "# 1. Initialize a local, persistent ChromaDB client\n",
    "client = PersistentClient(\n",
    "    path=\"./chroma_data\", \n",
    "    settings=Settings(), \n",
    "    tenant=DEFAULT_TENANT, \n",
    "    database=DEFAULT_DATABASE,\n",
    ")  #  [oai_citation:0‡Chroma Cookbook](https://cookbook.chromadb.dev/core/clients/?utm_source=chatgpt.com)\n",
    "\n",
    "# 2. Get or create your collection\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"golf_rules\", \n",
    "    metadata={\"description\": \"RAG store for Rules of Golf\"},\n",
    ")  #  [oai_citation:1‡Chroma Cookbook](https://cookbook.chromadb.dev/core/collections/?utm_source=chatgpt.com)\n",
    "\n",
    "# 3. Generate unique IDs for each text chunk\n",
    "ids = [f\"chunk_{i}\" for i in range(len(texts))]\n",
    "\n",
    "# 4. Add documents + embeddings (ids are now required)\n",
    "collection.add(\n",
    "    ids=ids,                   # list of unique string IDs\n",
    "    documents=texts,           # list of text chunks\n",
    "    metadatas=metadatas,       # list of metadata dicts\n",
    "    embeddings=embeddings,     # list of embedding vectors\n",
    ")  #  [oai_citation:2‡Learn R, Python & Data Science Online](https://www.datacamp.com/tutorial/chromadb-tutorial-step-by-step-guide?utm_source=chatgpt.com)\n",
    "\n",
    "# ──────────\n",
    "# No more `client.persist()` call is needed: PersistentClient writes are saved\n",
    "# automatically under your `path` directory as soon as you add data. \n",
    "# You’ll see a `chroma.sqlite3` and subfolders appear in ./chroma_data.  [oai_citation:3‡Chroma Cookbook](https://cookbook.chromadb.dev/core/storage-layout/?utm_source=chatgpt.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29020db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e789625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    NEO4J_URI, \n",
    "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "053da1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import re\n",
    "\n",
    "# Configure your Neo4j connection\n",
    "NEO4J_USER = NEO4J_USERNAME\n",
    "NEO4J_PASS = NEO4J_PASSWORD\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "\n",
    "def extract_rule_number(text):\n",
    "    m = re.match(r\"Rule (\\d+(\\.\\d+)*) –\", text)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "# 5.1 Create nodes for each rule chunk\n",
    "with driver.session() as session:\n",
    "    for d in docs:\n",
    "        # Only create one node per rule section header\n",
    "        rule_no = extract_rule_number(d[\"text\"][:100])\n",
    "        if rule_no:\n",
    "            session.run(\n",
    "                \"\"\"\n",
    "                MERGE (r:Rule {id:$rid})\n",
    "                ON CREATE SET r.text = $txt\n",
    "                \"\"\",\n",
    "                rid=rule_no, txt=d[\"text\"]\n",
    "            )\n",
    "    # 5.2 Link sections by parent_of (e.g., Rule 1 → Rule 1.1)\n",
    "    session.run(\"\"\"\n",
    "    MATCH (r1:Rule), (r2:Rule)\n",
    "    WHERE r2.id STARTS WITH r1.id + '.'\n",
    "    MERGE (r1)-[:PARENT_OF]->(r2)\n",
    "    \"\"\")\n",
    "    # 5.3 Detect explicit references \"see Rule X.Y\"\n",
    "    for d in docs:\n",
    "        refs = re.findall(r\"[Rr]ule (\\d+(\\.\\d+)*)\", d[\"text\"])\n",
    "        for ref, _ in refs:\n",
    "            rule_no = extract_rule_number(d[\"text\"][:100])\n",
    "            if rule_no:\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MATCH (a:Rule {id:$a}), (b:Rule {id:$b})\n",
    "                    MERGE (a)-[:REFERS_TO]->(b)\n",
    "                    \"\"\",\n",
    "                    a=rule_no, b=ref\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5d7e0",
   "metadata": {},
   "source": [
    "# Hybrid Retriever and RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d63a0864",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for MultiRetrievalQAChain\nreturn_source_documents\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.9/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 30\u001b[0m\n\u001b[1;32m     16\u001b[0m retriever_infos \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m     {\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     }\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 3) Build the multi‐retrieval QA chain without passing default_chain\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m multi_chain \u001b[38;5;241m=\u001b[39m \u001b[43mMultiRetrievalQAChain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_retrievers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriever_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_retriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_retriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_chain_llm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 4) Ask a question\u001b[39;00m\n\u001b[1;32m     41\u001b[0m result \u001b[38;5;241m=\u001b[39m multi_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat does Rule 5.3 say about starting the round?\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/miniforge3/envs/pdf_rag_m1/lib/python3.9/site-packages/langchain/chains/router/multi_retrieval_qa.py:98\u001b[0m, in \u001b[0;36mMultiRetrievalQAChain.from_retrievers\u001b[0;34m(cls, llm, retriever_infos, default_retriever, default_prompt, default_chain, default_chain_llm, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversation_llm must be provided if default_chain is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified. This API has been changed to avoid instantiating \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm = ChatOpenAI()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m     _default_chain \u001b[38;5;241m=\u001b[39m ConversationChain(\n\u001b[1;32m     93\u001b[0m         llm\u001b[38;5;241m=\u001b[39mdefault_chain_llm,\n\u001b[1;32m     94\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     95\u001b[0m         input_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m         output_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     97\u001b[0m     )\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouter_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouter_chain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdestination_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestination_chains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_default_chain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pdf_rag_m1/lib/python3.9/site-packages/langchain_core/load/serializable.py:110\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pdf_rag_m1/lib/python3.9/site-packages/pydantic/main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for MultiRetrievalQAChain\nreturn_source_documents\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.9/v/extra_forbidden"
     ]
    }
   ],
   "source": [
    "from langchain.chains.router.multi_retrieval_qa import MultiRetrievalQAChain  #  [oai_citation:0‡Introduction | 🦜️🔗 LangChain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.router.multi_retrieval_qa.MultiRetrievalQAChain.html?utm_source=chatgpt.com)\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1) Re-use your llm and prompt\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    template=(\n",
    "        \"Use the following context to answer the question precisely. \"\n",
    "        \"If it’s not in the context, say “I don’t know.”\\n\\n\"\n",
    "        \"{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2) Supply retriever_infos as before\n",
    "retriever_infos = [\n",
    "    {\n",
    "        \"name\": \"vector\",\n",
    "        \"description\": \"ADA embeddings + ChromaDB retrieval\",\n",
    "        \"retriever\": vector_retriever\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"graph\",\n",
    "        \"description\": \"Exact‐match Neo4j retrieval\",\n",
    "        \"retriever\": graph_retriever\n",
    "    }\n",
    "]\n",
    "\n",
    "# 3) Build the multi‐retrieval QA chain without passing default_chain\n",
    "multi_chain = MultiRetrievalQAChain.from_retrievers(\n",
    "    llm=llm,\n",
    "    retriever_infos=retriever_infos,\n",
    "    default_retriever=vector_retriever,\n",
    "    default_prompt=prompt,\n",
    "    default_chain_llm=llm,\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 4) Ask a question\n",
    "result = multi_chain.invoke({\"query\": \"What does Rule 5.3 say about starting the round?\"})\n",
    "print(result[\"result\"])\n",
    "# Inspect result[\"source_documents\"] for provenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf15ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e78670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 1) Install dependencies (run once) ─────────────────────────────────────\n",
    "# !pip install pymupdf langchain langchain-core langchain-openai chromadb neo4j\n",
    "\n",
    "# ─── 2) Imports & Setup ─────────────────────────────────────────────────────\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from neo4j import GraphDatabase\n",
    "from typing import Any\n",
    "\n",
    "from langchain.text_splitter                    import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings                       import OpenAIEmbeddings\n",
    "from chromadb                                  import PersistentClient\n",
    "from chromadb.config                           import Settings, DEFAULT_TENANT, DEFAULT_DATABASE\n",
    "from langchain_core.retrievers                  import BaseRetriever\n",
    "from langchain_core.documents                   import Document\n",
    "from langchain.vectorstores                     import Chroma\n",
    "from langchain.chains.router.multi_retrieval_qa import MultiRetrievalQAChain\n",
    "from langchain.chains.retrieval                 import create_retrieval_chain\n",
    "from langchain.chains.combine_documents.stuff   import create_stuff_documents_chain\n",
    "from langchain_core.prompts                     import PromptTemplate\n",
    "from langchain_openai                           import ChatOpenAI\n",
    "\n",
    "\n",
    "# ─── 4) Extract text from PDF ────────────────────────────────────────────────\n",
    "def extract_pages(pdf_path: str) -> list[str]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return [page.get_text(\"text\") for page in doc]\n",
    "\n",
    "pages = extract_pages(\"../data/Rules of Golf for 2019 (Final).pdf\")\n",
    "\n",
    "# ─── 5) Chunk text ────────────────────────────────────────────────────────────\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "docs = []\n",
    "for i, page in enumerate(pages):\n",
    "    for chunk in splitter.split_text(page):\n",
    "        docs.append({\"page\": i+1, \"text\": chunk})\n",
    "\n",
    "texts = [d[\"text\"] for d in docs]\n",
    "metadatas = [{\"page\": d[\"page\"]} for d in docs]\n",
    "\n",
    "# ─── 6) Generate embeddings ───────────────────────────────────────────────────\n",
    "embedder   = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "embeddings = embedder.embed_documents(texts)\n",
    "\n",
    "# ─── 7) Persist embeddings in ChromaDB ───────────────────────────────────────\n",
    "client = PersistentClient(\n",
    "    path=\"./chroma_data\",\n",
    "    settings=Settings(),\n",
    "    tenant=DEFAULT_TENANT,\n",
    "    database=DEFAULT_DATABASE,\n",
    ")\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"golf_rules\",\n",
    "    metadata={\"description\": \"RAG store for Rules of Golf\"},\n",
    ")\n",
    "ids = [f\"chunk_{i}\" for i in range(len(texts))]\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    documents=texts,\n",
    "    metadatas=metadatas,\n",
    "    embeddings=embeddings,\n",
    ")\n",
    "\n",
    "# ─── 8) Ingest rules into Neo4j ──────────────────────────────────────────────\n",
    "# NEO4J_URI  = \"bolt://localhost:7687\"\n",
    "# NEO4J_USER = \"neo4j\"\n",
    "# NEO4J_PASS = \"<YOUR_PASSWORD>\"\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n",
    "\n",
    "# At the top of your notebook, add:\n",
    "from typing import Any, Optional\n",
    "\n",
    "# Then replace the extract_rule_number definition:\n",
    "def extract_rule_number(text: str) -> Optional[str]:\n",
    "    m = re.match(r\"Rule (\\d+(\\.\\d+)*)\", text)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "with driver.session() as session:\n",
    "    # Create Rule nodes\n",
    "    for d in docs:\n",
    "        rid = extract_rule_number(d[\"text\"][:100])\n",
    "        if rid:\n",
    "            session.run(\n",
    "                \"MERGE (r:Rule {id:$rid}) ON CREATE SET r.text = $txt\",\n",
    "                rid=rid, txt=d[\"text\"]\n",
    "            )\n",
    "    # Parent relationships\n",
    "    session.run(\"\"\"\n",
    "    MATCH (r1:Rule), (r2:Rule)\n",
    "    WHERE r2.id STARTS WITH r1.id + '.'\n",
    "    MERGE (r1)-[:PARENT_OF]->(r2)\n",
    "    \"\"\")\n",
    "    # References\n",
    "    for d in docs:\n",
    "        src = extract_rule_number(d[\"text\"][:100])\n",
    "        if not src:\n",
    "            continue\n",
    "        for ref, _ in re.findall(r\"[Rr]ule (\\d+(\\.\\d+)*)\", d[\"text\"]):\n",
    "            session.run(\n",
    "                \"MATCH (a:Rule {id:$a}), (b:Rule {id:$b}) MERGE (a)-[:REFERS_TO]->(b)\",\n",
    "                a=src, b=ref\n",
    "            )\n",
    "\n",
    "# ─── 9) Define the Neo4jRetriever ────────────────────────────────────────────\n",
    "class Neo4jRetriever(BaseRetriever):\n",
    "    driver: Any\n",
    "    limit: int = 5\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> list[Document]:\n",
    "        keywords = query.split()\n",
    "        cypher = f\"\"\"\n",
    "        MATCH (r:Rule)\n",
    "        WHERE {\" OR \".join(f\"r.text CONTAINS '{w}'\" for w in keywords)}\n",
    "        RETURN r.id AS id, r.text AS text\n",
    "        LIMIT {self.limit}\n",
    "        \"\"\"\n",
    "        docs = []\n",
    "        with self.driver.session() as session:\n",
    "            for rec in session.run(cypher):\n",
    "                docs.append(Document(page_content=rec[\"text\"], metadata={\"rule_id\": rec[\"id\"]}))\n",
    "        return docs\n",
    "\n",
    "vector_retriever = Chroma(\n",
    "    collection_name=\"golf_rules\",\n",
    "    client=client,\n",
    "    embedding_function=embedder\n",
    ").as_retriever()\n",
    "\n",
    "graph_retriever  = Neo4jRetriever(driver=driver, limit=5)\n",
    "\n",
    "# ─── 10) Build QA chains ──────────────────────────────────────────────────────\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    template=(\n",
    "        \"Use the following context to answer the question precisely. \"\n",
    "        \"If it’s not in the context, say “I don’t know.”\\n\\n\"\n",
    "        \"{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    ")\n",
    "combine_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "vector_chain  = create_retrieval_chain(vector_retriever, combine_chain)\n",
    "graph_chain   = create_retrieval_chain(graph_retriever,  combine_chain)\n",
    "\n",
    "# ─── 11) Multi-retrieval router ─────────────────────────────────────────────\n",
    "multi_chain = MultiRetrievalQAChain.from_retrievers(\n",
    "    llm=llm,\n",
    "    retriever_infos=[\n",
    "        {\"name\": \"vector\", \"description\": \"ADA embeddings + ChromaDB\", \"retriever\": vector_retriever},\n",
    "        {\"name\": \"graph\",  \"description\": \"Exact-match Neo4j\",         \"retriever\": graph_retriever},\n",
    "    ],\n",
    "    default_retriever=vector_retriever,\n",
    "    default_prompt=prompt,\n",
    "    default_chain_llm=llm,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69ce7d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiRetrievalQAChain chain...\u001b[0m\n",
      "vector: {'query': 'What happens if the ball lands on an ant hill?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The provided context does not specifically address what happens if a ball lands on an ant hill. However, it does mention a \"dangerous animal condition\" involving dangerous animals such as poisonous snakes, stinging bees, fire ants, etc., where relief may be allowed if the animal near the ball could cause serious physical injury to the player.\n",
      "\n",
      "If the ant hill is considered a dangerous animal condition (e.g., fire ants that could cause harm), the player may be entitled to take relief under Rule 16.2.\n",
      "\n",
      "If the ant hill is not considered dangerous or does not interfere with the player's stance or swing, then the ball would generally be played as it lies.\n",
      "\n",
      "In summary, if the ant hill poses a dangerous animal condition, relief may be taken; otherwise, the ball must be played as it lies.\n"
     ]
    }
   ],
   "source": [
    "# ─── 12) Run a test query ──────────────────────────────────────────────────\n",
    "answer = multi_chain.run(\"What happens if the ball lands on an ant hill?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60f49698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiRetrievalQAChain chain...\u001b[0m\n",
      "vector: {'query': 'What happens if the ball lands near an alligator?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "If a player's ball is near a dangerous animal condition, such as an alligator, the player is allowed to take relief from interference by that dangerous animal condition under Rule 16.2. This relief can be taken no matter where the ball is on the course, except in certain situations where relief is not allowed (not specified here).\n",
      "\n",
      "So, if the ball lands near an alligator, the player may take relief to avoid serious physical injury by moving the ball according to the rules for dangerous animal conditions.\n"
     ]
    }
   ],
   "source": [
    "answer = multi_chain.run(\"What happens if the ball lands near an alligator?\")\n",
    "print(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35b64073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiRetrievalQAChain chain...\u001b[0m\n",
      "vector: {'query': 'How far is the drop from an alligator?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The provided context does not mention any specific rule or distance related to dropping a ball due to interference from an alligator or similar animal. Therefore, I do not have information on how far the drop should be from an alligator.\n"
     ]
    }
   ],
   "source": [
    "answer = multi_chain.run(\"How far is the drop from an alligator?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c888879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiRetrievalQAChain chain...\u001b[0m\n",
      "vector: {'query': 'What happens if the ball lands near an alligator?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "If the ball lands near an alligator, which is considered a dangerous animal condition, the player is allowed to take relief from interference by the dangerous animal condition. This relief can be taken no matter where the ball is on the course, except in certain situations where relief is not allowed (not specified here).\n",
      "\n",
      "The player may take relief under Rule 16.2b to avoid serious physical injury from the dangerous animal.\n"
     ]
    }
   ],
   "source": [
    "# ─── 12) Run a test query ──────────────────────────────────────────────────\n",
    "answer = multi_chain.run(\"What happens if the ball lands near an alligator?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62a191b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiRetrievalQAChain chain...\u001b[0m\n",
      "vector: {'query': 'What is the relief when your ball is in a sand trap with standing water inside and your ball is in standing water?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "According to the 2019 Rules of Golf, if your ball is in a penalty area such as a sand trap (bunker) with standing water, you are entitled to relief options under Rule 17 (Relief from Penalty Areas).\n",
      "\n",
      "Specifically:\n",
      "\n",
      "- Since the ball is in a penalty area (the sand trap with standing water), you may take relief by either playing the ball as it lies in the penalty area (if possible), or taking penalty relief outside the penalty area with a one-stroke penalty.\n",
      "\n",
      "- If you choose to take relief without penalty, you may drop the ball in the penalty area (bunker) at the nearest point of complete relief from the standing water, not nearer the hole than the reference point.\n",
      "\n",
      "- If there is no point of complete relief in the bunker, you may take relief outside the bunker on the back-on-the-line relief option, with a one-stroke penalty.\n",
      "\n",
      "- Alternatively, if you choose to take penalty relief outside the penalty area, you drop the ball outside the penalty area on the line from the hole through the point where the ball last crossed the edge of the penalty area, with a one-stroke penalty.\n",
      "\n",
      "In summary, you have the option to:\n",
      "\n",
      "1. Play the ball as it lies in the standing water in the bunker (if possible).\n",
      "\n",
      "2. Take free relief within the bunker if there is a point of complete relief from the standing water (rare in standing water situations).\n",
      "\n",
      "3. Take penalty relief outside the bunker with a one-stroke penalty by dropping on the back-on-the-line relief area.\n",
      "\n",
      "Therefore, standing water in a bunker is treated as a penalty area condition, and relief options are provided under Rule 17 with or without penalty depending on the relief chosen.\n",
      "\n",
      "Note: There is no free relief simply because the ball is in standing water in a bunker unless the Committee has adopted a local rule allowing relief for abnormal course conditions in bunkers (which is not standard).\n"
     ]
    }
   ],
   "source": [
    "answer = multi_chain.run(\"What is the relief when your ball is in a sand trap with standing water inside and your ball is in standing water?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a4cebad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiRetrievalQAChain chain...\u001b[0m\n",
      "vector: {'query': 'What do the rules say about alligators?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The rules of golf do not specifically mention alligators. However, alligators would be considered \"animals\" under the rules, as they are living members of the animal kingdom (reptiles). If an alligator or its presence creates a dangerous animal condition, Rule 16.2 on interference by a dangerous animal condition would apply, allowing relief for the player. \n",
      "\n",
      "In general, animals (including alligators) and their holes or disturbances may be considered abnormal course conditions or loose impediments depending on the situation, and the rules provide guidance on relief in those cases. But there is no specific rule that addresses alligators by name.\n"
     ]
    }
   ],
   "source": [
    "answer = multi_chain.run(\"What do the rules say about alligators?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "201bd35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiRetrievalQAChain chain...\u001b[0m\n",
      "vector: {'query': 'What is the relief from a dangerous animal?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Relief from a dangerous animal condition is allowed under Rule 16.2 when a dangerous animal (such as poisonous snakes, stinging bees, alligators, fire ants, or bears) near a ball could cause serious physical injury to the player if they had to play the ball as it lies.\n",
      "\n",
      "Here is how relief works:\n",
      "\n",
      "1. **When the ball is anywhere except a penalty area:**\n",
      "   - The player may take relief under Rule 16.1b, c, or d, depending on whether the ball is in the general area, in a bunker, or on the putting green.\n",
      "\n",
      "2. **When the ball is in a penalty area:**\n",
      "   - **Free Relief (Playing from Inside Penalty Area):** The player may take free relief under Rule 16.1b, but the nearest point of complete relief and the relief area must be inside the penalty area.\n",
      "   - **Penalty Relief (Playing from Outside Penalty Area):** The player may take penalty relief under Rule 17.1d. If interference by a dangerous animal condition still exists where the ball would be played after taking this penalty relief outside the penalty area, the player may take further relief as described above without additional penalty.\n",
      "\n",
      "The \"nearest point of complete relief\" means the nearest point (not nearer the hole) where the dangerous animal condition does not exist.\n",
      "\n",
      "**Penalty for playing from a wrong place in breach of Rule 16.2 is the general penalty under Rule 14.7a.**\n",
      "\n",
      "In summary, a player is entitled to free relief from interference by a dangerous animal condition, either by dropping the ball at the nearest point of complete relief or by taking penalty relief if the ball is in a penalty area, ensuring the player avoids serious physical injury.\n"
     ]
    }
   ],
   "source": [
    "answer = multi_chain.run(\"What is the relief from a dangerous animal?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1486b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiRetrievalQAChain chain...\u001b[0m\n",
      "vector: {'query': 'What is the club-length relief from a dangerous animal?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "When taking relief from a dangerous animal condition under the Rules of Golf, the player is allowed to take free relief by dropping the ball within a relief area defined by the nearest point of complete relief. This relief area is measured as one club-length from that reference point, subject to certain limits.\n",
      "\n",
      "Specifically:\n",
      "\n",
      "- The relief area is one club-length from the nearest point of complete relief.\n",
      "- The relief area must be in a location allowed by the rules, for example:\n",
      "  - It must not be nearer the hole than the reference point.\n",
      "  - It must be in the same area of the course as the ball (general area, bunker, or putting green), depending on where the ball lies.\n",
      "  - It must not be in a penalty area or bunker if the ball is not originally there.\n",
      "  - It must be a place where there is no interference from the dangerous animal condition.\n",
      "- When measuring the club-length relief area, the player may measure directly across obstacles like ditches or objects but not through ground that slopes up and down.\n",
      "\n",
      "Therefore, the club-length relief from a dangerous animal condition is one club-length from the nearest point of complete relief, within the allowed relief area and subject to the above limitations.\n"
     ]
    }
   ],
   "source": [
    "answer = multi_chain.run(\"What is the club-length relief from a dangerous animal?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153910cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_rag_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
