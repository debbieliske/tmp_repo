# Design Decisions for Azure Cognitive Search

## Index Design Decisions
- **Key Field**: 
  - Chose `chunk_id` as the key field for the index, ensuring each document chunk has a unique identifier.
- **Field Types**: 
  - Defined fields like `content` and `document_id` with appropriate types (e.g., String, Collection, DateTimeOffset).
- **Vector Field Configuration**: 
  - Added a `content_vector` field with 1536 dimensions to store embeddings generated by the AzureOpenAIEmbeddingSkill.
  - Associated the vector field with a default vector search profile using HNSW (Hierarchical Navigable Small World) parameters.
- **Retrievable and Searchable Fields**: 
  - Made `content` searchable and retrievable for full-text and semantic search.
  - Included metadata fields (e.g., `last_modified_date`, `blob_path`) for filtering and retrieving relevant information.

## Data Source Decisions
- **Type**: 
  - Chose Azure Blob Storage as the data source.
- **Data Container**: 
  - Configured the data source to use a specific blob container.
- **Connection String**: 
  - Required the secure connection string for accessing the blob container.

## Skillset Design Decisions
- **Skill Order**: 
  - Skills were defined in sequence to ensure dependencies are resolved:
    - **OcrSkill**: Extract text from images.
    - **MergeSkill**: Combine OCR-extracted text with native document text.
    - **SplitSkill**: Divide the combined text into manageable chunks (pages).
    - **AzureOpenAIEmbeddingSkill**: Generate embeddings for each chunk.
- **OCR Language and Orientation**: 
  - Configured the OcrSkill to detect orientation and use `en` (English) as the default language.
- **Text Splitting**: 
  - Chose `TextSplitMode.PAGES` for the SplitSkill with a `maximum_page_length` of 2000 characters to ensure chunks are manageable.
- **Embedding Resource**: 
  - Used an Azure OpenAI resource for embedding generation, specifying the deployment name and API key.

## Indexer Decisions
- **Field Mappings**: 
  - Mapped metadata fields from blob storage (e.g., `metadata_storage_path`, `metadata_storage_last_modified`) to index fields (`document_id`, `last_modified_date`).
- **Output Field Mappings**: 
  - Configured output mappings to align skillset outputs with index fields:
    - `/document/pages/* → content`
    - `/document/pages/*/content_vector → content_vector`
    - `/document/pages/* → chunk_id` (with a `concat` function for uniqueness).
- **Target Index**: 
  - Configured the indexer to target the custom-defined index.

## Query and Search Configuration
- **Semantic Search**: 
  - Enabled semantic search with a configuration that prioritizes the `content` field for relevance.
- **Vector Search**: 
  - Integrated vector search using AzureOpenAIVectorizer for similarity queries, leveraging OpenAI embeddings.

## General Decisions
- **Tooling and SDK**: 
  - Used the Azure SDK for Python to define and implement all components programmatically.
- **Error Handling**: 
  - Included the ability to monitor skillset outputs and validate the correctness of intermediate outputs (e.g., chunking and embedding generation).
- **Scalability**: 
  - Designed the pipeline to handle large and complex documents by chunking text and using embeddings.

## Logging and Monitoring Decisions
- **Diagnostic Settings**: 
  - Assumed diagnostic logs would be configured for monitoring query and indexer performance.
- **Log Analytics Integration**: 
  - (Implied) Log Analytics Workspace would be used for advanced monitoring and troubleshooting.

## Potential Areas for Further Refinement
- **Chunking Logic**: 
  - Consider whether the `maximum_page_length` of 2000 characters is optimal for all document types.
- **Skillset Configurations**: 
  - Review the default language (`en`) and orientation detection in OcrSkill for multi-language support.
- **Index Fields**: 
  - Add fields like `file_type` or `author` if they are critical for search and filtering.